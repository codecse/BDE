{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_ahATLKNrIM",
        "outputId": "f2b0c3ae-dba6-4196-e7a7-e49f22cc599f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "# Create a Spark context\n",
        "sc = SparkContext()\n",
        "\n",
        "# Create RDD from python list\n",
        "lst = range(5, 20)\n",
        "list_rdd1 = sc.parallelize(lst, 3)\n",
        "\n",
        "# Copy RDD\n",
        "rdd2 = list_rdd1\n",
        "\n",
        "# Read from a file\n",
        "# r3 = sc.textFile('/user/cloudera/mr/file1')\n",
        "rdd1 = sc.textFile('file1.txt')\n",
        "\n",
        "# Actions and Transformations\n",
        "# Actions: first(), take(n), collect(), count(), reduce(func), takeOrdered(n, [ordering])\n",
        "print(\"First element:\", list_rdd1.first())\n",
        "print(\"First 3 elements:\", list_rdd1.take(3))\n",
        "print(\"All elements:\", rdd2.collect())\n",
        "print(\"Count:\", rdd2.count())\n",
        "x = rdd2.reduce(lambda i, j: i + j)\n",
        "print(\"Reduced value:\", x)\n",
        "\n",
        "# Transformations: distinct(), filter(func), map(func), flatMap(func), union(otherDataset), intersection(otherDataset), groupByKey([numTasks]), reduceByKey(func, [numTasks]), join(otherDataset, [numTasks]), cartesian(otherDataset)\n",
        "lst = [('modi', 'pm'), ('Babu', 'cm'), ('Naidu', 'vp'), ('kcr', 'cm'), ('narasimham', 'governor'),\n",
        "       ('uma', 'minister'), ('ktr', 'minister'), ('Babu', 'cm'), ('narasimham', 'governor')]\n",
        "rdd_lst = sc.parallelize(lst)\n",
        "\n",
        "# Distinct\n",
        "distinct_rddlist = rdd_lst.distinct()\n",
        "print(\"Distinct elements:\", distinct_rddlist.collect())\n",
        "\n",
        "# Filter\n",
        "filter_rddlist = rdd_lst.filter(lambda element: element[1] == 'cm')\n",
        "print(\"Filtered elements:\", filter_rddlist.collect())\n",
        "\n",
        "# Map\n",
        "map_rddlist = rdd_lst.map(lambda x: (x[1], x[0]))\n",
        "print(\"Mapped elements:\", map_rddlist.collect())\n",
        "\n",
        "# SortByKey\n",
        "sortbykey_rdd = map_rddlist.sortByKey()\n",
        "print(\"Sorted by key:\", sortbykey_rdd.collect())\n",
        "\n",
        "# GroupByKey\n",
        "groupbykey_rdd = map_rddlist.groupByKey()\n",
        "print(\"Grouped by key:\")\n",
        "for x in groupbykey_rdd.collect():\n",
        "    print(x[0], list(x[1]))\n",
        "\n",
        "# ReduceByKey\n",
        "reducebykey_rdd = map_rddlist.reduceByKey(lambda x, y: x + y)\n",
        "print(\"Reduced by key:\", reducebykey_rdd.collect())\n",
        "\n",
        "# FlatMap\n",
        "rdd1 = sc.parallelize(range(5, 10))\n",
        "flatmap_rdd3 = rdd1.flatMap(lambda i: (i, i + 5, i * 5))\n",
        "print(\"FlatMap result:\", flatmap_rdd3.collect())\n",
        "\n",
        "# TakeOrdered\n",
        "print(\"TakeOrdered (asc):\", flatmap_rdd3.takeOrdered(7))\n",
        "print(\"TakeOrdered (desc):\", flatmap_rdd3.takeOrdered(flatmap_rdd3.count(), lambda x: -x))\n",
        "\n",
        "# Union and Intersection\n",
        "rdd2 = sc.parallelize(range(8, 15))\n",
        "rddunion = rdd1.union(rdd2)\n",
        "print(\"Union:\", rddunion.collect())\n",
        "\n",
        "rddintersection = rdd1.intersection(rdd2)\n",
        "print(\"Intersection:\", rddintersection.collect())\n",
        "\n",
        "# Cartesian\n",
        "rddcartesian = rdd1.cartesian(rdd2)\n",
        "print(\"Cartesian:\", rddcartesian.collect())\n",
        "\n",
        "# JOIN\n",
        "rdd1 = sc.parallelize([(1, 8.5), (2, 7.7), (3, 9), (5, 6.5)])\n",
        "rdd2 = sc.parallelize([(1, 'cse'), (3, 'ece'), (4, 'me'), (5, 'eee')])\n",
        "\n",
        "rddjoin = rdd1.join(rdd2)\n",
        "print(\"JOIN result:\", rddjoin.collect())\n",
        "\n",
        "rddleftouter = rdd1.leftOuterJoin(rdd2)\n",
        "print(\"Left Outer JOIN result:\", rddleftouter.collect())\n",
        "\n",
        "rddrightouter = rdd1.rightOuterJoin(rdd2)\n",
        "print(\"Right Outer JOIN result:\", rddrightouter.collect())\n",
        "\n",
        "rddfullouter = rdd1.fullOuterJoin(rdd2)\n",
        "print(\"Full Outer JOIN result:\", rddfullouter.collect())\n",
        "\n",
        "# Word Count Example\n",
        "# x = sc.textFile(\"/user/cloudera/wc\")\n",
        "x = sc.textFile(\"file2.txt\")\n",
        "a = x.flatMap(lambda line: line.split(\" \"))\n",
        "b = a.map(lambda word: (word, 1))\n",
        "c = b.reduceByKey(lambda a, b: a + b)\n",
        "# c.saveAsTextFile(\"/user/cloudera/output\")\n",
        "\n",
        "# Stop Spark Context\n",
        "sc.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIFb1QOAOQJP",
        "outputId": "c3d7090e-bc9d-4a3d-9ff5-94561683dfa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First element: 5\n",
            "First 3 elements: [5, 6, 7]\n",
            "All elements: [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "Count: 15\n",
            "Reduced value: 180\n",
            "Distinct elements: [('Naidu', 'vp'), ('uma', 'minister'), ('ktr', 'minister'), ('modi', 'pm'), ('Babu', 'cm'), ('kcr', 'cm'), ('narasimham', 'governor')]\n",
            "Filtered elements: [('Babu', 'cm'), ('kcr', 'cm'), ('Babu', 'cm')]\n",
            "Mapped elements: [('pm', 'modi'), ('cm', 'Babu'), ('vp', 'Naidu'), ('cm', 'kcr'), ('governor', 'narasimham'), ('minister', 'uma'), ('minister', 'ktr'), ('cm', 'Babu'), ('governor', 'narasimham')]\n",
            "Sorted by key: [('cm', 'Babu'), ('cm', 'kcr'), ('cm', 'Babu'), ('governor', 'narasimham'), ('governor', 'narasimham'), ('minister', 'uma'), ('minister', 'ktr'), ('pm', 'modi'), ('vp', 'Naidu')]\n",
            "Grouped by key:\n",
            "governor ['narasimham', 'narasimham']\n",
            "minister ['uma', 'ktr']\n",
            "pm ['modi']\n",
            "cm ['Babu', 'kcr', 'Babu']\n",
            "vp ['Naidu']\n",
            "Reduced by key: [('governor', 'narasimhamnarasimham'), ('minister', 'umaktr'), ('pm', 'modi'), ('cm', 'BabukcrBabu'), ('vp', 'Naidu')]\n",
            "FlatMap result: [5, 10, 25, 6, 11, 30, 7, 12, 35, 8, 13, 40, 9, 14, 45]\n",
            "TakeOrdered (asc): [5, 6, 7, 8, 9, 10, 11]\n",
            "TakeOrdered (desc): [45, 40, 35, 30, 25, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5]\n",
            "Union: [5, 6, 7, 8, 9, 8, 9, 10, 11, 12, 13, 14]\n",
            "Intersection: [8, 9]\n",
            "Cartesian: [(5, 8), (5, 9), (5, 10), (6, 8), (6, 9), (6, 10), (5, 11), (5, 12), (5, 13), (5, 14), (6, 11), (6, 12), (6, 13), (6, 14), (7, 8), (7, 9), (7, 10), (8, 8), (9, 8), (8, 9), (8, 10), (9, 9), (9, 10), (7, 11), (7, 12), (7, 13), (7, 14), (8, 11), (9, 11), (8, 12), (8, 13), (9, 12), (9, 13), (8, 14), (9, 14)]\n",
            "JOIN result: [(1, (8.5, 'cse')), (5, (6.5, 'eee')), (3, (9, 'ece'))]\n",
            "Left Outer JOIN result: [(1, (8.5, 'cse')), (5, (6.5, 'eee')), (2, (7.7, None)), (3, (9, 'ece'))]\n",
            "Right Outer JOIN result: [(4, (None, 'me')), (1, (8.5, 'cse')), (5, (6.5, 'eee')), (3, (9, 'ece'))]\n",
            "Full Outer JOIN result: [(4, (None, 'me')), (1, (8.5, 'cse')), (5, (6.5, 'eee')), (2, (7.7, None)), (3, (9, 'ece'))]\n"
          ]
        }
      ]
    }
  ]
}